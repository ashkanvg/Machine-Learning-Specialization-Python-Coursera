1- What is Neural Networks and Deep Learning
2- Demand Prediction
	- Ex: finding top sellers
	- layer
		- input layer
		- hidden layers
		- output layer
	- activation

	(picture 1,2,3)

4- Recognizing Images
	- Example

	

5- Neural Netwrok Layer
	- [] --> refer to number of layer
	- input layers number -> 0 --> input vector (x) is a[0]
	- if final layer output a^[2] > 0.5 --> yes  else No
	(picture 4,5)
	- aj^[l]=g(wj[l].a[l-1]+bj[l])
		+ l: layer number
		+ j: unit number of a layer
		+ w,b parameter of layer l and unit j
		+ g: sigmoid function --> now we saye "activation function" 
	(picture 6,7)
	

6- Neural Networks Inference (Making Predictions) by Forward Propagation


7- Tensorflow and Keras
	- inference in code:
		2 layer model:
		+ x = np.array([200,17])
		+ layer_1 = Dense(unit=3,activation='sigmoid')
		+ a1 = layer_1(x)	 # vector 

		+ layer_2 = Dense(unit=1, activation = "sigmoid')
		+ a2 = layer_2(a1)

		+ if a2>=0.5: yhat =1
		+ else: yhat = 0
		(picture 8)

		3 layer model (digit classification):
		+ x = np.array (...)
		+ layer_1 = Dense(unit=25,activation='sigmoid')
		+ a1 = layer_1(x)	# vector and tensorflow style
		+ a2.numpy() 		# numpy style

		+ layer_2 = Dense(unit=15, activation = "sigmoid')
		+ a2 = layer_2(a1)

		+ layer_3 = Dense(unit=1, activation = "sigmoid')
		+ a3 = layer_2(a2)

		+ if a3>=0.5: yhat =1
		+ else: yhat = 0

	- numpy
		- for Tensorflow we use 2d arry for function	--> x = np.array([[200,17]])
		- for sckit learn we use 1d array for function	--> x = np.array([200,17])
		(picture 9)

8- Building a Neurl Network Tensorflow (another way)
	- code:
		+ layer_1 = Dense(units=3,activation="sigmoid")
		+ layer_2 = Dense(units=3,activation="sigmoid")
		+ model = Sequential([layer_1,layer_2])
		+ x = np.array([[...]]); 	# 2d
		+ y = np.array([...]);		# 1d
		+ model.compile(...) 		# next week
		+ model.fit(x,y)		# train
		+ x_new = np.array([[...]])	# 2d
		+ model.predict(x_new)		# predict

	- make it beter:
		+ model = Sequential([
				Dense(units=3,activation="sigmoid", name="layer1"),
				Dense(units=3,activation="sigmoid", name="layer2")])
		+ x = np.array([[...]]); 				# 2d
		+ y = np.array([...]);					# 1d
		+ model.summary() 					# summary
		+ model.compile(...) 					# next week
		+ model.fit(x,y)					# train
		+ x_new = np.array([[...]])				# 2d
		+ model.predict(x_new)					# predict

	- usefull functions:
		
		+ W1, b1 = model.get_layer("layer1").get_weights()	# get weights
		+ W2, b2 = model.get_layer("layer2").get_weights()	# get weights

		+ model.get_layer("layer1").set_weights([W1,b1])	# set weights
		+ model.get_layer("layer2").set_weights([W2,b2])	# set weights


9-Neural Network implementation in Python
	(picture 10,11) (lab: C2_W1_Lab03_CoffeeRoasting_Numpy)
	- notation:
		+ capital W refer to Matrix
		+ small w refer to vector

	- dense function:
		+ def my_dense(a_in, W, b, g):    		
    			units = W.shape[1]
    			a_out = np.zeros(units)

    			for j in range(units):               
        			w = W[:,j]                                    
        			z = np.dot(w, a_in) + b[j]         
        			a_out[j] = g(z)               
        
    			return(a_out)




10- AGI: Aritficial general Interlligence
11- Vectorization
	- At = A.T (in python)
	- Z = AT @ W (or Z=np.matmul(AT.W)) 

	- dense function:
		+ def my_dense_v(A_in, W, b, g):
    			Z = np.matmul(A_in,W) + b    
    			A_out = g(Z)
    			return(A_out)